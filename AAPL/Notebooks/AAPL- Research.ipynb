{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7,
     21,
     51
    ],
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# ??\n",
    "import backtrader as bt\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import time\n",
    "\n",
    "class firstStrategy(bt.Strategy):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rsi = bt.indicators.RSI_SMA(self.data.close, period=21)\n",
    "\n",
    "    def next(self):\n",
    "        if not self.position:\n",
    "            if self.rsi < 30:\n",
    "                self.buy(size=100)\n",
    "        else:\n",
    "            if self.rsi > 70:\n",
    "                self.sell(size=100)\n",
    "\n",
    "\n",
    "def printTradeAnalysis(analyzer):\n",
    "    '''\n",
    "    Function to print the Technical Analysis results in a nice format.\n",
    "    '''\n",
    "    #Get the results we are interested in\n",
    "    total_open = analyzer.total.open\n",
    "    total_closed = analyzer.total.closed\n",
    "    total_won = analyzer.won.total\n",
    "    total_lost = analyzer.lost.total\n",
    "    win_streak = analyzer.streak.won.longest\n",
    "    lose_streak = analyzer.streak.lost.longest\n",
    "    pnl_net = round(analyzer.pnl.net.total,2)\n",
    "    strike_rate = (total_won / total_closed) * 100\n",
    "    #Designate the rows\n",
    "    h1 = ['Total Open', 'Total Closed', 'Total Won', 'Total Lost']\n",
    "    h2 = ['Strike Rate','Win Streak', 'Losing Streak', 'PnL Net']\n",
    "    r1 = [total_open, total_closed,total_won,total_lost]\n",
    "    r2 = [strike_rate, win_streak, lose_streak, pnl_net]\n",
    "    #Check which set of headers is the longest.\n",
    "    if len(h1) > len(h2):\n",
    "        header_length = len(h1)\n",
    "    else:\n",
    "        header_length = len(h2)\n",
    "    #Print the rows\n",
    "    print_list = [h1,r1,h2,r2]\n",
    "    row_format =\"{:<15}\" * (header_length + 1)\n",
    "    print(\"Trade Analysis Results:\")\n",
    "    for row in print_list:\n",
    "        print(row_format.format('',*row))\n",
    "\n",
    "def printSQN(analyzer):\n",
    "    sqn = round(analyzer.sqn,2)\n",
    "    print('SQN: {}'.format(sqn))\n",
    "\n",
    "#Variable for our starting cash\n",
    "startcash = 100000\n",
    "\n",
    "#Create an instance of cerebro\n",
    "cerebro = bt.Cerebro()\n",
    "\n",
    "#Add our strategy\n",
    "cerebro.addstrategy(firstStrategy)\n",
    "\n",
    "#Get Apple data from Yahoo Finance.\n",
    "os.chdir('C:\\\\Users\\\\asus\\\\Documents\\\\Python Projects\\\\Trading - Research and Backtest\\\\AAPL')\n",
    "datapath = os.getcwd() + '\\\\Databases\\\\'\n",
    "data     = bt.feeds.GenericCSVData(dataname = datapath + 'AAPL-5min.csv',\n",
    "                                   timeframe = bt.TimeFrame.Minutes,\n",
    "                                   compression = 5,\n",
    "                                   #sessionstart = datetime.time(9, 35, 0),\n",
    "                                   #sessionend = datetime.time(15, 30, 0),\n",
    "                                   reverse = False, datetime = 0, time = 6,\n",
    "                                   high = 2, low = 3, open = 1, close = 4, volume = 5, openinterest = -1,\n",
    "                                   nullvalue = 0.0, #fromdate = datetime.datetime(2020, 4, 15), todate = datetime.datetime(2020, 4, 16),\n",
    "                                   dtformat = ('%Y-%m-%d'), tmformat = ('%H:%M:%S')\n",
    "                                  )\n",
    "\n",
    "#Add the data to Cerebro\n",
    "cerebro.adddata(data)\n",
    "\n",
    "# Set our desired cash start\n",
    "cerebro.broker.setcash(startcash)\n",
    "\n",
    "# Add the analyzers we are interested in\n",
    "cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name=\"ta\")\n",
    "cerebro.addanalyzer(bt.analyzers.SQN, _name=\"sqn\")\n",
    "\n",
    "# Run over everything\n",
    "strategies = cerebro.run()\n",
    "firstStrat = strategies[0]\n",
    "\n",
    "# print the analyzers\n",
    "printTradeAnalysis(firstStrat.analyzers.ta.get_analysis())\n",
    "printSQN(firstStrat.analyzers.sqn.get_analysis())\n",
    "\n",
    "#Get final portfolio Value\n",
    "portvalue = cerebro.broker.getvalue()\n",
    "\n",
    "#Print out the final result\n",
    "print('Final Portfolio Value: ${}'.format(portvalue))\n",
    "\n",
    "#Finally plot the end results\n",
    "cerebro.plot(style='candlestick')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.066561Z",
     "start_time": "2020-08-09T09:06:30.104206Z"
    },
    "code_folding": [
     0
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import time\n",
    "import decimal\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyoff\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='onedork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Correlations and Covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.081566Z",
     "start_time": "2020-08-09T09:07:01.069574Z"
    },
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Move columns functions\n",
    "def movecol(df, cols_to_move=[], ref_col='', place='After'):\n",
    "    cols = df.columns.tolist()\n",
    "    if place == 'After':\n",
    "        seg1 = cols[:list(cols).index(ref_col) + 1]\n",
    "        seg2 = cols_to_move\n",
    "    if place == 'Before':\n",
    "        seg1 = cols[:list(cols).index(ref_col)]\n",
    "        seg2 = cols_to_move + [ref_col]\n",
    "    seg1 = [i for i in seg1 if i not in seg2]\n",
    "    seg3 = [i for i in cols if i not in seg1 + seg2]\n",
    "    return(df[seg1 + seg2 + seg3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.834977Z",
     "start_time": "2020-08-09T09:07:01.089562Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'date' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-34b796b17845>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mequities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1969\u001b[0m                 \u001b[0m_validate_usecols_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1971\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_noconvert_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_set_noconvert_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2048\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2049\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2050\u001b[1;33m                     \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2051\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2052\u001b[0m                 \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_set\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2026\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2027\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2029\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_noconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'date' is not in list"
     ]
    }
   ],
   "source": [
    "# List of US Stocks\n",
    "us_tickers = ['AAPL', 'AMZN', 'FB', 'NFLX', 'SPY', 'TSLA', 'V']\n",
    "equities = {}\n",
    "for ticker in us_tickers:\n",
    "    equities.update({ticker: {}})\n",
    "    path = 'C:\\\\Users\\\\asus\\\\Documents\\\\Python Projects\\\\Trading - Research and Backtest\\\\'+ticker\n",
    "    os.chdir(path)\n",
    "    datapath = os.getcwd() + '\\\\Databases\\\\'\n",
    "    files = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(datapath):\n",
    "        files.extend(filenames)\n",
    "        break\n",
    "    for file in files:\n",
    "            _ = pd.read_csv(datapath + file, index_col = 'date', parse_dates = True)\n",
    "            equities[ticker].update({file.split('-')[1].split('.')[0]: _})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.843973Z",
     "start_time": "2020-08-09T09:06:30.122Z"
    },
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "# Merge Data\n",
    "start = '2020-06-01'\n",
    "end = '2020-07-28'\n",
    "intervals = ['5min', '15min', '30min', '60min', 'daily']\n",
    "merge_df = {}\n",
    "for interval in intervals:\n",
    "    if interval == 'daily':\n",
    "        _merge = equities['AAPL'][interval][['4. close']]\\\n",
    "                     .loc[start:end].rename(columns={'4. close':'4. close_AAPL'}).reset_index()\n",
    "        for ticker in us_tickers:\n",
    "            if not ticker == 'AAPL':\n",
    "                b = equities[ticker][interval][['4. close']]\\\n",
    "                    .loc[start:end].rename(columns={'4. close':('4. close_'+ticker)}).reset_index()\n",
    "                _merge = _merge.merge(b, left_on=['date'], right_on=['date'], how='outer')\n",
    "        _merge.set_index('date', inplace=True)\n",
    "        merge_df.update({interval: _merge})\n",
    "    else:\n",
    "        _merge = equities['AAPL'][interval][['4. close', 'time']]\\\n",
    "                     .loc[start:end].rename(columns={'4. close':'4. close_AAPL'}).reset_index()\n",
    "        for ticker in us_tickers:\n",
    "            if not ticker == 'AAPL':\n",
    "                b = equities[ticker][interval][['4. close', 'time']]\\\n",
    "                    .loc[start:end].rename(columns={'4. close':('4. close_'+ticker)}).reset_index()\n",
    "                _merge = _merge.merge(b, left_on=['date', 'time'], right_on=['date', 'time'], how='outer')\n",
    "        _merge['datetime'] = pd.to_datetime(_merge['date'].astype(str)+' '+_merge['time'])\n",
    "        _merge = movecol(_merge, cols_to_move=['datetime', 'date', 'time'], ref_col='4. close_AAPL', place='Before')\\\n",
    "                 .set_index('datetime')\n",
    "        merge_df.update({interval: _merge})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.847971Z",
     "start_time": "2020-08-09T09:06:30.132Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find Covariance between each stocks closing price\n",
    "covariance = merge_df['daily'].dropna().cov()\n",
    "# Overall Plot\n",
    "plot = sns.heatmap(covariance,cmap='coolwarm',annot=True)\n",
    "plot.set(ylim=(len(covariance)-0.005, -0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.850968Z",
     "start_time": "2020-08-09T09:06:30.138Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Individual Plot\n",
    "vec1 = covariance['4. close_V']\n",
    "fig, ax = plt.subplots()\n",
    "plot = sns.heatmap([vec1], cmap='coolwarm', annot=True, xticklabels=vec1.index.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.853968Z",
     "start_time": "2020-08-09T09:06:30.144Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Find Correlation between each stocks closing price\n",
    "interval = 'daily'\n",
    "correlation = merge_df[interval].dropna().corr(method='pearson')\n",
    "print('Correlation of {} closing price of stocks for the period {} to {}'.format(interval, start, end))\n",
    "# Overall Plot\n",
    "plt.subplots(figsize=(10, 6))\n",
    "plot = sns.heatmap(correlation,cmap='coolwarm',annot=True)\n",
    "plot.set(ylim=(len(correlation)-0.005, -0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.856965Z",
     "start_time": "2020-08-09T09:06:30.150Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Individual Plot\n",
    "base_stock = 'AAPL'\n",
    "vec1 = correlation['4. close_'+base_stock]\n",
    "print('Correlation of {} closing price for the period {} to {} towards other equities'.format(base_stock, start, end))\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plot = sns.heatmap([vec1], cmap='coolwarm', annot=True, xticklabels=vec1.index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.860962Z",
     "start_time": "2020-08-09T09:06:30.156Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Rolling Individual Plot\n",
    "plot_data = []\n",
    "window = 5\n",
    "for ticker in us_tickers:\n",
    "    rolling_r = merge_df[interval]['4. close_'+base_stock].rolling(window=window, center=False)\\\n",
    "                .corr(merge_df[interval]['4. close_'+ticker])\n",
    "    _ = go.Scatter(x=rolling_r.dropna().index.to_list(), y=rolling_r.dropna(), name=base_stock+' and '+ticker)\n",
    "    plot_data.append(_)\n",
    "plot_layout = go.Layout(title = 'Rolling correlation of %s stock ' % base_stock)\n",
    "fig = go.Figure(data = plot_data, layout = plot_layout)\n",
    "pyoff.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granger Causality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Lagged Cross Correlation â€” assessing signal dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.862961Z",
     "start_time": "2020-08-09T09:06:30.161Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def crosscorr(datax, datay, lag=0, wrap=False):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Shifted data filled with NaNs \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    if wrap:\n",
    "        shiftedy = datay.shift(lag)\n",
    "        shiftedy.iloc[:lag] = datay.iloc[-lag:].values\n",
    "        return datax.corr(shiftedy)\n",
    "    else: \n",
    "        return datax.corr(datay.shift(lag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.864961Z",
     "start_time": "2020-08-09T09:06:30.166Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Leader Follower Dynamic\n",
    "d1 = merge_df[interval]['4. close_'+'AAPL']\n",
    "d2 = merge_df[interval]['4. close_'+'SPY']\n",
    "rs = [crosscorr(d1,d2, lag) for lag in range(-int(len(d1)/2),int(len(d1)/2)+1)]\n",
    "offset = np.ceil(len(rs)/2)-np.argmax(rs)\n",
    "f,ax=plt.subplots(figsize=(14,3))\n",
    "ax.plot(rs)\n",
    "ax.axvline(np.ceil(len(rs)/2)-1,color='k',linestyle='--',label='Center')\n",
    "ax.axvline(np.argmax(rs),color='r',linestyle='--',label='Peak synchrony')\n",
    "ax.set(title=f'Offset = {int(offset)} \\n{base_stock} leads <> SPY leads', xlabel='Offset',ylabel='Pearson r')\n",
    "ax.set_xticklabels([int(item-int(len(d1)/2)) for item in ax.get_xticks()]);\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.867959Z",
     "start_time": "2020-08-09T09:06:30.171Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Rolling window time lagged cross correlation\n",
    "window_size =  14 #samples\n",
    "t_start = 0\n",
    "t_end = t_start + window_size\n",
    "step_size = 1\n",
    "rss=[]\n",
    "while t_end < len(merge_df[interval]):\n",
    "    d1 = merge_df[interval]['4. close_'+'AAPL'].iloc[t_start:t_end]\n",
    "    d2 = merge_df[interval]['4. close_'+'SPY'].iloc[t_start:t_end]\n",
    "    rs = [crosscorr(d1,d2, lag, wrap=False) for lag in range(-int(window_size/2),int(window_size/2)+1)]\n",
    "    rss.append(rs)\n",
    "    t_start = t_start + step_size\n",
    "    t_end = t_end + step_size\n",
    "rss = pd.DataFrame(rss)\n",
    "\n",
    "f,ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(rss,cmap='RdBu_r',ax=ax, annot=True)\n",
    "ax.set(title=f'Rolling Windowed Time Lagged Cross Correlation',xlabel='(<-- '+base_stock+')  Offset  (SPY -->)',ylabel='Epochs', \n",
    "       ylim=(len(rss)-0.005, -0.05))\n",
    "ax.set_xticklabels(np.arange(-int(window_size/2), int(window_size/2)+1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:07:01.870957Z",
     "start_time": "2020-08-09T09:06:30.175Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Time Lagged summary\n",
    "_1 = rss.iloc[:, :7].mean(axis=1)\n",
    "_2 = rss.iloc[:, 8:-1].mean(axis=1)\n",
    "_3 = rss.iloc[:, 7]\n",
    "summary = pd.DataFrame([_1, _3, _2], index=['Lead AAPL', 'Neutral', 'Lead SPY']).T\n",
    "f,ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(summary,cmap='coolwarm',ax=ax, annot=True)\n",
    "ax.set(ylim=(len(rss)-0.005, -0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "550px",
    "left": "0px",
    "top": "91.51px",
    "width": "173.889px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
