{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T08:13:42.854466Z",
     "start_time": "2020-08-01T08:13:29.503079Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "api_key = '092YO8Y7KS4D36UD'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import pandas_datareader as wb\n",
    "from pathlib import Path\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T08:13:45.711251Z",
     "start_time": "2020-08-01T08:13:45.703250Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Set Data Interval\n",
    "start = '2019-01-01'\n",
    "end = '2020-07-29'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## United States Stocks\n",
    "AlphaVantage API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:06:17.445189Z",
     "start_time": "2020-07-30T12:06:17.435198Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Countdown function\n",
    "def countdown(t):\n",
    "    while t:\n",
    "        mins, secs = divmod(t, 60)\n",
    "        timeformat = '{:02d}:{:02d}'.format(mins, secs)\n",
    "        print(timeformat, end='\\r')\n",
    "        time.sleep(1)\n",
    "        t -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:07:33.661130Z",
     "start_time": "2020-07-30T12:07:33.623133Z"
    },
    "code_folding": [
     0,
     2,
     21
    ]
   },
   "outputs": [],
   "source": [
    "# With or without Confirmation\n",
    "if False: # With confirmation\n",
    "    def Get_Intraday_US(ticker, interval, start, end):\n",
    "        for ticker in ticker:\n",
    "            for interval in interval:\n",
    "                ts = TimeSeries(key = 'api_key', output_format = 'pandas')\n",
    "                data, meta_data = ts.get_intraday(ticker, interval = interval, outputsize = 'full', )\n",
    "                data.sort_index(ascending = True, inplace = True)\n",
    "                data['time'] = list(map(lambda x: data.index[x].strftime('%Y-%m-%d %H:%M:%S').split()[1], range(0, len(data.index))))\n",
    "                data['time'] = pd.to_datetime(data['time'], format = '%H:%M:%S').dt.time\n",
    "                data.index = list(map(lambda x: data.index[x].strftime('%Y-%m-%d %H:%M:%S').split()[0], range(0, len(data.index))))\n",
    "                data.index = pd.to_datetime(data.index)\n",
    "                current_data_path = Path('C:\\\\Users\\\\asus\\\\Documents\\\\Python Projects\\\\Trading - Research and Backtest\\\\'+ticker+ \\\n",
    "                                          '\\\\Databases\\\\'+ticker+'-'+interval+'.csv')\n",
    "                if not current_data_path.exists():\n",
    "                    print(\"Oops, file doesn't exist!\")\n",
    "                    confirm = input('Would you like to create a new '+ticker+interval+' ? (Yes/No) \\n')\n",
    "                    if confirm.lower() == 'yes':\n",
    "                        data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = True, index_label = 'date' )\n",
    "                else:\n",
    "                    print(\"Yay, the file exists!\")\n",
    "                    confirm = input('Would you like to add '+ticker+'-'+interval+' from '+start+' to '+end+'? \\n' + \\\n",
    "                            'Please re-check the input as this might re-write the whole database (Yes/No)\\n')\n",
    "                    if confirm.lower() == 'yes':\n",
    "                        #current_data = pd.read_csv(current_data_path, index_col = 'date', parse_dates = True)\n",
    "                        #new_data = data.loc[start : end]\n",
    "                        new_data = data.loc[start : end]\n",
    "                        new_data.to_csv(current_data_path, mode = 'a', header = False, date_format = ('%Y-%m-%d'), index = True,\n",
    "                                        index_label = 'date')\n",
    "                        updated_data = pd.read_csv(current_data_path)\n",
    "                        updated_data = updated_data.drop_duplicates(subset = ['date', 'time'], keep = 'first')\n",
    "                        updated_data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = False)\n",
    "                        pass\n",
    "                    pass\n",
    "                pass\n",
    "else: # Without confirmation\n",
    "    def Get_Intraday_US(ticker, interval, start, end): \n",
    "        for ticker in ticker:\n",
    "            for interval in interval:\n",
    "                ts = TimeSeries(key = 'api_key', output_format = 'pandas')\n",
    "                data, meta_data = ts.get_intraday(ticker, interval = interval, outputsize = 'full', )\n",
    "                data.sort_index(ascending = True, inplace = True)\n",
    "                data['time'] = list(map(lambda x: data.index[x].strftime('%Y-%m-%d %H:%M:%S').split()[1], range(0, len(data.index))))\n",
    "                data['time'] = pd.to_datetime(data['time'], format = '%H:%M:%S').dt.time\n",
    "                data.index = list(map(lambda x: data.index[x].strftime('%Y-%m-%d %H:%M:%S').split()[0], range(0, len(data.index))))\n",
    "                data.index = pd.to_datetime(data.index)\n",
    "                current_data_path = Path('C:\\\\Users\\\\asus\\\\Documents\\\\Python Projects\\\\Trading - Research and Backtest\\\\'+ticker+ \\\n",
    "                                          '\\\\Databases\\\\'+ticker+'-'+interval+'.csv')\n",
    "                if not current_data_path.exists():\n",
    "                    print('Oops, file doesn\\'t exist. Create new '+ticker+'-'+interval+' file')\n",
    "                    data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = True, index_label = 'date' )\n",
    "                else:\n",
    "                    print('Yay, the file exists! Updating '+ticker+'-'+interval+' file')\n",
    "                    new_data = data.loc[start : end]\n",
    "                    new_data.to_csv(current_data_path, mode = 'a', header = False, date_format = ('%Y-%m-%d'), index = True,\n",
    "                                    index_label = 'date')\n",
    "                    updated_data = pd.read_csv(current_data_path)\n",
    "                    updated_data = updated_data.drop_duplicates(subset = ['date', 'time'], keep = 'first')\n",
    "                    updated_data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = False)\n",
    "                    pass\n",
    "                pass\n",
    "            pass    \n",
    "        print('Get data done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T08:08:31.338195Z",
     "start_time": "2020-07-29T08:08:31.201277Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def Data_to_csv(ticker, data, interval):\n",
    "    previous_data_path = Path('C:\\\\Users\\\\asus\\\\Documents\\\\Python Projects\\\\Trading - Research and Backtest\\\\'+ticker+ \\\n",
    "                              '\\\\Databases\\\\'+ticker+'-'+interval)  \n",
    "    data = data.loc[start : end]\n",
    "    \n",
    "    data.to_csv(previous_data_path, mode = 'a', header = False, date_format = ('%Y-%m-%d'), \n",
    "                index = True, index_label = 'date' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T08:20:53.190693Z",
     "start_time": "2020-07-29T08:08:31.347190Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# List of US tickers\n",
    "us_tickers = ['AAPL', 'AMZN', 'FB', 'NFLX', 'SPY', 'TSLA', 'V']\n",
    "# Retrieve intraday data, 5 retrieves per minute and 500 calls per day\n",
    "interval = ['5min', '15min', '30min', '60min']\n",
    "for ticker in us_tickers:\n",
    "    countdown(90)\n",
    "    Get_Intraday_US([ticker], interval, start, end)\n",
    "print('Get Intraday Data Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T08:20:53.215661Z",
     "start_time": "2020-07-29T08:20:53.194672Z"
    },
    "code_folding": [
     2
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Get_Daily_US Data functions. With or without confirmations\n",
    "if False: # With confirmation\n",
    "    def Get_Daily_US(ticker): \n",
    "        for ticker in ticker:\n",
    "            ts = TimeSeries(key = 'api_key', output_format = 'pandas')\n",
    "            data, meta_data = ts.get_daily_adjusted(ticker, outputsize = 'full', )\n",
    "            data.sort_index(ascending = True, inplace = True)\n",
    "            current_data_path = Path('C:\\\\Users\\\\asus\\\\Documents\\\\Python Projects\\\\Trading - Research and Backtest\\\\'+ticker+ \\\n",
    "                                 '\\\\Databases\\\\'+ticker+'-'+'daily'+'.csv')\n",
    "            if not current_data_path.exists():\n",
    "                confirm = input('Oops, file doesn\\'t exist. Create new '+ticker+'-daily file? (Yes/No) \\n')\n",
    "                if confirm.lower() == 'yes':\n",
    "                    data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = True, index_label = 'date' )\n",
    "            else:\n",
    "                confirm = input('Would you like to update '+ticker+'-daily ? (Yes/No) \\n')\n",
    "                if confirm.lower() == 'yes':\n",
    "                    data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = True, index_label = 'date' )\n",
    "else: # Without confirmation\n",
    "    def Get_Daily_US(ticker): \n",
    "        for ticker in ticker:\n",
    "            ts = TimeSeries(key = 'api_key', output_format = 'pandas')\n",
    "            data, meta_data = ts.get_daily_adjusted(ticker, outputsize = 'full', )\n",
    "            data.sort_index(ascending = True, inplace = True)\n",
    "            current_data_path = Path('C:\\\\Users\\\\asus\\\\Documents\\\\Python Projects\\\\Trading - Research and Backtest\\\\'+ticker+ \\\n",
    "                                 '\\\\Databases\\\\'+ticker+'-'+'daily'+'.csv')\n",
    "            if not current_data_path.exists():\n",
    "                print('Oops, file doesn\\'t exist. Create new '+ticker+'-daily file')\n",
    "                data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = True, index_label = 'date' )\n",
    "            else:\n",
    "                print('Updating '+ticker+'-daily')\n",
    "                data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = True, index_label = 'date' )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T08:24:36.260976Z",
     "start_time": "2020-07-29T08:20:53.220657Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve daily data, 5 retrieves per minute and 500 calls per day\n",
    "countdown(90)\n",
    "counter = 0\n",
    "for ticker in us_tickers:\n",
    "    if counter == 5:\n",
    "        countdown(90)\n",
    "        counter = 0\n",
    "    Get_Daily_US([ticker])\n",
    "    counter += 1\n",
    "print('Get Daily Data US Stocks Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Indonesia Stocks\n",
    "pandas_datareader -yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:22:38.704795Z",
     "start_time": "2020-07-30T12:22:38.684810Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Get_Daily_ID Data functions. With or without confirmations\n",
    "if False: # With confirmation\n",
    "    def Get_Daily_ID(ticker): \n",
    "        for ticker in ticker:\n",
    "            data = wb.DataReader(ticker, 'yahoo', start, end)\n",
    "            data.sort_index(ascending = True, inplace = True)\n",
    "            current_data_path = Path('C:\\\\Users\\\\asus\\\\Documents\\\\Python Projects\\\\Trading - Research and Backtest\\\\'+ticker+ \\\n",
    "                                 '\\\\Databases\\\\'+ticker+'-'+'daily'+'.csv')\n",
    "            if not current_data_path.exists():\n",
    "                confirm = input('Oops, file doesn\\'t exist. Create new '+ticker+'-daily file? (Yes/No) \\n')\n",
    "                if confirm.lower() == 'yes':\n",
    "                    data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = True, index_label = 'date' )\n",
    "            else:\n",
    "                confirm = input('Would you like to update '+ticker+'-daily ? (Yes/No) \\n')\n",
    "                if confirm.lower() == 'yes':\n",
    "                    data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = True, index_label = 'date' )\n",
    "else: # Without confirmation\n",
    "    def Get_Daily_ID(ticker): \n",
    "        for ticker in ticker:\n",
    "            data = wb.DataReader(ticker, 'yahoo', start, end)\n",
    "            data.sort_index(ascending = True, inplace = True)\n",
    "            current_data_path = Path('C:\\\\Users\\\\asus\\\\Documents\\\\Python Projects\\\\Trading - Research and Backtest\\\\'+ticker+ \\\n",
    "                                 '\\\\Databases\\\\'+ticker+'-'+'daily'+'.csv')\n",
    "            if not current_data_path.exists():\n",
    "                print('Oops, file doesn\\'t exist. Create new '+ticker+'-daily file')\n",
    "                data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = True, index_label = 'date' )\n",
    "            else:\n",
    "                print('Updating '+ticker+'-daily')\n",
    "                data.to_csv(current_data_path, date_format = ('%Y-%m-%d'), index = True, index_label = 'date' )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:22:47.597859Z",
     "start_time": "2020-07-30T12:22:39.915075Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating ^JKSE-daily\n",
      "Updating BBCA.JK-daily\n",
      "Updating GGRM.JK-daily\n",
      "Updating JPFA.JK-daily\n",
      "Updating TLKM.JK-daily\n",
      "Get Daily Data ID Stocks Completed\n"
     ]
    }
   ],
   "source": [
    "# Retrieve daily data\n",
    "id_tickers = ['^JKSE', 'BBCA.JK', 'GGRM.JK', 'JPFA.JK', 'TLKM.JK']\n",
    "for ticker in id_tickers:\n",
    "    Get_Daily_ID([ticker])\n",
    "print('Get Daily Data ID Stocks Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T11:58:39.279040Z",
     "start_time": "2020-07-30T11:58:39.257051Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "id_tickers = ['^JKSE', 'BBCA.JK', 'GGRM.JK', 'JPFA.JK', 'TLKM.JK']\n",
    "def Get_Intraday_ID()\n",
    "# for ticker in id_tickers:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "550px",
    "left": "42.9861px",
    "top": "177.778px",
    "width": "303.542px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
